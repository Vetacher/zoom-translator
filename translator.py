import azure.cognitiveservices.speech as speechsdk
from typing import Optional, List, Callable
import asyncio
import logging

from app.config import settings

logger = logging.getLogger(__name__)


class AzureSpeechTranslator:
    """–ö–ª–∞—Å—Å –¥–ª—è —Ä–∞–±–æ—Ç—ã —Å Azure Speech Translation"""
    
    def __init__(self, source_language: str = None, target_languages: List[str] = None):
        """
        –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä—É–µ—Ç Azure Speech Translator
        
        Args:
            source_language: –ò—Å—Ö–æ–¥–Ω—ã–π —è–∑—ã–∫ (–Ω–∞–ø—Ä–∏–º–µ—Ä, 'ru-RU')
            target_languages: –°–ø–∏—Å–æ–∫ —è–∑—ã–∫–æ–≤ –¥–ª—è –ø–µ—Ä–µ–≤–æ–¥–∞ (–Ω–∞–ø—Ä–∏–º–µ—Ä, ['en-US', 'de-DE'])
        """
        self.source_language = source_language or settings.default_source_language
        self.target_languages = target_languages or [settings.default_target_language]
        self.custom_vocabulary = []
        
        # –ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è Azure Speech
        self.speech_config = speechsdk.translation.SpeechTranslationConfig(
            subscription=settings.azure_speech_key,
            region=settings.azure_speech_region
        )
        
        # –£—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ–º —è–∑—ã–∫–∏
        self.speech_config.speech_recognition_language = self.source_language
        for target_lang in self.target_languages:
            # –ü—Ä–µ–æ–±—Ä–∞–∑—É–µ–º —Ñ–æ—Ä–º–∞—Ç —è–∑—ã–∫–∞: 'en-US' -> 'en'
            target_code = target_lang.split('-')[0]
            self.speech_config.add_target_language(target_code)
        
        # –ù–∞—Å—Ç—Ä–æ–π–∫–∏ –∫–∞—á–µ—Å—Ç–≤–∞
        self.speech_config.set_property(
            speechsdk.PropertyId.Speech_SegmentationSilenceTimeoutMs, "500"
        )
        
        self.recognizer = None
        self.is_running = False
    
    def set_custom_vocabulary(self, vocabulary: List[str]):
        """
        –£—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ—Ç –∫–∞—Å—Ç–æ–º–Ω—ã–π –≤–æ–∫–∞–±—É–ª—è—Ä –¥–ª—è —É–ª—É—á—à–µ–Ω–∏—è —Ä–∞—Å–ø–æ–∑–Ω–∞–≤–∞–Ω–∏—è
        
        Args:
            vocabulary: –°–ø–∏—Å–æ–∫ —Å–ø–µ—Ü–∏–∞–ª—å–Ω—ã—Ö —Å–ª–æ–≤/—Ñ—Ä–∞–∑
        """
        self.custom_vocabulary = vocabulary
        
        if self.custom_vocabulary and self.recognizer:
            # –°–æ–∑–¥–∞—ë–º phrase list –¥–ª—è —É–ª—É—á—à–µ–Ω–∏—è —Ä–∞—Å–ø–æ–∑–Ω–∞–≤–∞–Ω–∏—è
            phrase_list = speechsdk.PhraseListGrammar.from_recognizer(self.recognizer)
            for phrase in self.custom_vocabulary:
                phrase_list.addPhrase(phrase)
            
            logger.info(f"Custom vocabulary set: {len(self.custom_vocabulary)} phrases")
    
    async def start_translation_from_audio_stream(
        self, 
        audio_stream,
        on_recognizing: Optional[Callable] = None,
        on_recognized: Optional[Callable] = None,
        on_translated: Optional[Callable] = None
    ):
        """
        –ù–∞—á–∏–Ω–∞–µ—Ç –ø–µ—Ä–µ–≤–æ–¥ –∏–∑ –∞—É–¥–∏–æ –ø–æ—Ç–æ–∫–∞
        
        Args:
            audio_stream: –ê—É–¥–∏–æ –ø–æ—Ç–æ–∫ –¥–ª—è –æ–±—Ä–∞–±–æ—Ç–∫–∏
            on_recognizing: Callback –¥–ª—è –ø—Ä–æ–º–µ–∂—É—Ç–æ—á–Ω—ã—Ö —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ —Ä–∞—Å–ø–æ–∑–Ω–∞–≤–∞–Ω–∏—è
            on_recognized: Callback –¥–ª—è —Ñ–∏–Ω–∞–ª—å–Ω—ã—Ö —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ —Ä–∞—Å–ø–æ–∑–Ω–∞–≤–∞–Ω–∏—è
            on_translated: Callback –¥–ª—è —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ –ø–µ—Ä–µ–≤–æ–¥–∞
        """
        try:
            # –ù–∞—Å—Ç—Ä–∞–∏–≤–∞–µ–º –∞—É–¥–∏–æ –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—é
            audio_config = speechsdk.audio.AudioConfig(stream=audio_stream)
            
            # –°–æ–∑–¥–∞—ë–º recognizer
            self.recognizer = speechsdk.translation.TranslationRecognizer(
                translation_config=self.speech_config,
                audio_config=audio_config
            )
            
            # –ü—Ä–∏–º–µ–Ω—è–µ–º –∫–∞—Å—Ç–æ–º–Ω—ã–π –≤–æ–∫–∞–±—É–ª—è—Ä –µ—Å–ª–∏ –µ—Å—Ç—å
            if self.custom_vocabulary:
                self.set_custom_vocabulary(self.custom_vocabulary)
            
            # –ü–æ–¥–∫–ª—é—á–∞–µ–º callback'–∏
            def recognizing_handler(evt):
                if on_recognizing:
                    result = {
                        'text': evt.result.text,
                        'language': self.source_language
                    }
                    asyncio.create_task(on_recognizing(result))
            
            def recognized_handler(evt):
                if evt.result.reason == speechsdk.ResultReason.TranslatedSpeech:
                    # –ò—Å—Ö–æ–¥–Ω—ã–π —Ç–µ–∫—Å—Ç
                    source_text = evt.result.text
                    
                    # –ü–µ—Ä–µ–≤–æ–¥—ã
                    translations = {}
                    for target_lang in self.target_languages:
                        target_code = target_lang.split('-')[0]
                        if target_code in evt.result.translations:
                            translations[target_lang] = evt.result.translations[target_code]
                    
                    if on_recognized:
                        asyncio.create_task(on_recognized({
                            'source_text': source_text,
                            'source_language': self.source_language
                        }))
                    
                    if on_translated and translations:
                        asyncio.create_task(on_translated({
                            'source_text': source_text,
                            'translations': translations
                        }))
                    
                    logger.info(f"Recognized: {source_text}")
                    logger.info(f"Translations: {translations}")
            
            def canceled_handler(evt):
                logger.error(f"Translation canceled: {evt.reason}")
                if evt.reason == speechsdk.CancellationReason.Error:
                    logger.error(f"Error details: {evt.error_details}")
                self.is_running = False
            
            # –ü–æ–¥–∫–ª—é—á–∞–µ–º –æ–±—Ä–∞–±–æ—Ç—á–∏–∫–∏
            self.recognizer.recognizing.connect(recognizing_handler)
            self.recognizer.recognized.connect(recognized_handler)
            self.recognizer.canceled.connect(canceled_handler)
            
            # –ó–∞–ø—É—Å–∫–∞–µ–º –Ω–µ–ø—Ä–µ—Ä—ã–≤–Ω–æ–µ —Ä–∞—Å–ø–æ–∑–Ω–∞–≤–∞–Ω–∏–µ
            logger.info("Starting continuous translation...")
            self.recognizer.start_continuous_recognition()
            self.is_running = True
            
            # –ñ–¥—ë–º –ø–æ–∫–∞ —Ä–∞–±–æ—Ç–∞–µ—Ç
            while self.is_running:
                await asyncio.sleep(0.1)
        
        except Exception as e:
            logger.error(f"Error in translation: {e}")
            self.is_running = False
            raise
    
    def stop_translation(self):
        """–û—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ—Ç –ø–µ—Ä–µ–≤–æ–¥"""
        if self.recognizer and self.is_running:
            logger.info("Stopping translation...")
            self.recognizer.stop_continuous_recognition()
            self.is_running = False
    
    @staticmethod
    def get_supported_languages():
        """–í–æ–∑–≤—Ä–∞—â–∞–µ—Ç —Å–ø–∏—Å–æ–∫ –ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ–º—ã—Ö —è–∑—ã–∫–æ–≤"""
        return {
            'ru-RU': 'üá∑üá∫ –†—É—Å—Å–∫–∏–π',
            'en-US': 'üá∫üá∏ English (US)',
            'en-GB': 'üá¨üáß English (UK)',
            'de-DE': 'üá©üá™ Deutsch',
            'fr-FR': 'üá´üá∑ Fran√ßais',
            'es-ES': 'üá™üá∏ Espa√±ol',
            'it-IT': 'üáÆüáπ Italiano',
            'zh-CN': 'üá®üá≥ ‰∏≠Êñá',
            'ja-JP': 'üáØüáµ Êó•Êú¨Ë™û',
            'ko-KR': 'üá∞üá∑ ÌïúÍµ≠Ïñ¥',
            'pt-BR': 'üáßüá∑ Portugu√™s',
            'ar-SA': 'üá∏üá¶ ÿßŸÑÿπÿ±ÿ®Ÿäÿ©',
            'nl-NL': 'üá≥üá± Nederlands',
            'pl-PL': 'üáµüá± Polski',
            'tr-TR': 'üáπüá∑ T√ºrk√ße'
        }


class AudioStreamWrapper:
    """–û–±—ë—Ä—Ç–∫–∞ –¥–ª—è –∞—É–¥–∏–æ –ø–æ—Ç–æ–∫–∞ –¥–ª—è —Ä–∞–±–æ—Ç—ã —Å Azure Speech SDK"""
    
    def __init__(self):
        self.audio_buffer = []
        self.is_closed = False
    
    def write(self, audio_data):
        """–î–æ–±–∞–≤–ª—è–µ—Ç –∞—É–¥–∏–æ –¥–∞–Ω–Ω—ã–µ –≤ –±—É—Ñ–µ—Ä"""
        if not self.is_closed:
            self.audio_buffer.append(audio_data)
    
    def read(self, size):
        """–ß–∏—Ç–∞–µ—Ç –∞—É–¥–∏–æ –¥–∞–Ω–Ω—ã–µ –∏–∑ –±—É—Ñ–µ—Ä–∞"""
        if self.audio_buffer:
            return self.audio_buffer.pop(0)
        return b''
    
    def close(self):
        """–ó–∞–∫—Ä—ã–≤–∞–µ—Ç –ø–æ—Ç–æ–∫"""
        self.is_closed = True
